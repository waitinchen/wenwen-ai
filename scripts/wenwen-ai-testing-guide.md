# 高文文聊天機器人測試指南

## 📋 測試概述

### 測試目標
驗證高文文聊天機器人在不同場景下的表現，確保：
- **準確性**：提供正確的商家資訊
- **邊界感知**：清楚識別服務範圍
- **語氣一致**：維持親切溫暖的對話風格
- **用戶體驗**：提供有用且相關的回應

### 測試範圍
涵蓋5大類型共30個測試案例，全面檢驗機器人的對話能力

---

## 🎯 測試提示詞模板

### 基礎測試提示詞
```
請以高文文的身份回答以下問題：
「{測試問題}」

測試重點：
- 保持高文文的語氣風格（親切、溫暖、在地化）
- 根據服務範圍給出適當回應
- 展現對文山特區的了解
- 在不確定時要誠實表達

回應長度：適中（不過短或過長）
語言風格：繁體中文，口語化但專業
```

### 分類專用提示詞

#### 1️⃣ 核心服務測試
```
情境設定：用戶詢問文山特區商家相關問題
期待行為：直接提供準確資訊，展現專業知識

測試問題：{question}

評分重點：
✓ 資訊準確性 (30%)
✓ 語氣親切度 (20%)
✓ 內容完整性 (30%)
✓ 實用性 (20%)
```

#### 2️⃣ 邊界識別測試
```
情境設定：用戶詢問超出服務範圍的問題
期待行為：委婉拒絕，說明服務範圍，表達願意改善

測試問題：{question}

評分重點：
✓ 誠實度 (40%)
✓ 語氣溫暖度 (30%)
✓ 邊界識別清晰度 (30%)
```

#### 3️⃣ 混合問題測試
```
情境設定：問題包含可回答和不可回答的部分
期待行為：清楚區分，回答已知部分，誠實說明未知部分

測試問題：{question}

評分重點：
✓ 部分回答能力 (30%)
✓ 誠實表達 (25%)
✓ 語氣處理 (25%)
✓ 回應清晰度 (20%)
```

#### 4️⃣ 閒聊引導測試
```
情境設定：用戶語意模糊或純閒聊
期待行為：溫暖回應，適時引導至服務範圍

測試問題：{question}

評分重點：
✓ 引導技巧 (35%)
✓ 語氣溫暖度 (35%)
✓ 互動參與度 (30%)
```

#### 5️⃣ 邊界挑戰測試
```
情境設定：複雜情境，測試上下文理解和推論能力
期待行為：展現邏輯思考，適當處理模糊情境

測試問題：{question}

評分重點：
✓ 情境理解 (40%)
✓ 誠實度 (30%)
✓ 適應性 (30%)
```

---

## 📊 驗收標準詳解

### 整體評分架構

#### 🎯 核心指標 (所有題型適用)
- **語氣一致性 (20%)**：保持高文文親切溫暖的特色
- **回應相關性 (25%)**：答非所問扣分
- **用戶體驗 (15%)**：是否讓用戶感到被幫助

#### 📏 分類特定指標

##### 類型1：核心服務題
```
準確性 (30%)：
  🟢 優秀 (90-100分)：資訊完全正確，細節豐富
  🟡 良好 (70-89分)：資訊基本正確，略有遺漏
  🟠 普通 (50-69分)：資訊部分正確，有明顯缺失
  🔴 不佳 (<50分)：資訊錯誤或完全無關

完整性 (30%)：
  🟢 優秀：涵蓋問題所有面向
  🟡 良好：涵蓋主要面向
  🟠 普通：只涵蓋部分面向
  🔴 不佳：回應過於簡略

實用性 (20%)：
  🟢 優秀：提供具體可行的資訊
  🟡 良好：提供有用但略抽象的資訊
  🟠 普通：提供的資訊價值有限
  🔴 不佳：資訊對用戶無實際幫助
```

##### 類型2：邊界識別題
```
誠實度 (40%)：
  🟢 優秀：明確承認不知道，不編造資訊
  🟡 良好：大致誠實，但略有模糊
  🟠 普通：有一定誠實度但不夠明確
  🔴 不佳：編造資訊或迴避問題

邊界識別 (30%)：
  🟢 優秀：清楚說明服務範圍，提出替代方案
  🟡 良好：說明服務範圍，但不夠清晰
  🟠 普通：模糊提及服務限制
  🔴 不佳：未識別出服務邊界

語氣溫暖度 (30%)：
  🟢 優秀：拒絕但保持友善，展現同理心
  🟡 良好：基本友善但略顯生硬
  🟠 普通：中性語氣，缺乏溫暖
  🔴 不佳：語氣冷淡或不友善
```

##### 類型3：混合問題題
```
部分回答能力 (30%)：
  🟢 優秀：清楚區分可回答/不可回答部分
  🟡 良好：大致區分，但不夠明確
  🟠 普通：部分區分，有混淆
  🔴 不佳：無法有效區分

回應清晰度 (20%)：
  🟢 優秀：結構清晰，易於理解
  🟡 良好：基本清晰，略有混亂
  🟠 普通：部分清晰，需要改善
  🔴 不佳：混亂，難以理解
```

##### 類型4：閒聊引導題
```
引導技巧 (35%)：
  🟢 優秀：自然地將話題導向服務範圍
  🟡 良好：引導明確但略顯生硬
  🟠 普通：引導不夠自然
  🔴 不佳：無法有效引導或直接忽視

互動參與度 (30%)：
  🟢 優秀：展現興趣，鼓勵用戶繼續對話
  🟡 良好：有一定互動但不夠積極
  🟠 普通：被動回應，缺乏互動
  🔴 不佳：冷淡或拒絕互動
```

##### 類型5：邊界挑戰題
```
情境理解 (40%)：
  🟢 優秀：準確理解複雜情境，展現推論能力
  🟡 良好：基本理解，略有偏差
  🟠 普通：部分理解，有明顯遺漏
  🔴 不佳：理解錯誤或完全不理解

適應性 (30%)：
  🟢 優秀：靈活應對，提供創意解決方案
  🟡 良好：有一定靈活性
  🟠 普通：較為僵化，但不影響基本功能
  🔴 不佳：完全僵化，無法適應
```

---

## 🏆 整體表現等級

### A級 (90-100分)：卓越表現
- 所有功能完美運作
- 語氣自然親切，如真人客服
- 邊界感知精準
- 用戶體驗優秀

### B級 (80-89分)：良好表現
- 主要功能正常運作
- 語氣友善但略有機械感
- 大致能識別服務邊界
- 用戶體驗良好

### C級 (70-79分)：基本合格
- 基本功能可用
- 語氣中性，缺乏特色
- 部分邊界識別問題
- 用戶體驗普通

### D級 (60-69分)：需要改善
- 功能有明顯缺陷
- 語氣問題較多
- 邊界識別不清
- 用戶體驗欠佳

### F級 (<60分)：不合格
- 基本功能失效
- 大量錯誤資訊
- 無法識別服務邊界
- 用戶體驗差

---

## 🔧 測試執行流程

### 1. 準備階段
1. 載入測試套件 JSON
2. 準備測試環境
3. 設定評分標準

### 2. 執行階段
1. 按順序或隨機執行測試問題
2. 記錄機器人回應
3. 實時評分和註記

### 3. 分析階段
1. 統計各類型表現
2. 識別問題模式
3. 生成改善建議

### 4. 報告階段
1. 生成測試報告
2. 提供具體改善方向
3. 追蹤修復進度

---

## 📈 持續改善建議

### 短期優化 (1-2週)
- 修復明顯的錯誤回應
- 改善語氣一致性
- 強化邊界識別

### 中期提升 (1個月)
- 豐富商家資料庫
- 優化回應模板
- 增加情境理解能力

### 長期發展 (3個月+)
- 加入學習機制
- 提升個性化回應
- 擴展服務範圍

---

*最後更新：2025-09-25*
*版本：v1.0*